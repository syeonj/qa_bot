import streamlit as st
import os
from dotenv import load_dotenv
from streamlit_chat import message
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler

# Load environment variables
load_dotenv()

# Streamlit app settings
st.set_page_config(
    page_title="ì§í„°ë·°",
    page_icon=":smiley:",
    layout="wide",
    initial_sidebar_state="expanded",
)

# OpenAI API ì„¤ì • (í•„ìš”ì‹œ)
# openai.api_key = os.environ.get("OPENAI_API_KEY")

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "user_prompt_history" not in st.session_state:
    st.session_state["user_prompt_history"] = []

if "chat_answer_history" not in st.session_state:
    st.session_state["chat_answer_history"] = []

if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

# QA Chain ì„¤ì • (í•œ ë²ˆë§Œ í•™ìŠµ)
if "qa_chain" not in st.session_state:
    # YouTube ë™ì˜ìƒ URL ë° ì˜¤ë””ì˜¤ ì €ì¥ ê²½ë¡œ
    urls = [
      'https://www.youtube.com/watch?v=YxYWhn8gpGA&list=PLC9G30QJs92gI1LQUPJmYrv0sQzIIcGV8&index=9'
    ]

    save_dir = "./youtube_audios/"

    # ë™ì˜ìƒì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    from langchain_community.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader
    from langchain_community.document_loaders.generic import GenericLoader
    from langchain_community.document_loaders.parsers import OpenAIWhisperParser
    from functools import reduce
    from langchain_community.vectorstores import FAISS
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_openai import OpenAIEmbeddings

    loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())
    docs = loader.load()

    # Define word pairs to replace
    replace_pairs = {
        'ì œì •íŒ€': 'ì¬ì •íŒ€', 'ì•„ë¦¬ì ¤ëµì‹¤':'REì „ëµì‹¤', 'ì‹ êµ¬ì‚¬ì—…': 'ì‹ ê·œì‚¬ì—…', 'ê¸°ê´€í•œ': 'ê¸°ë°˜í•œ', 'í˜ë¥´ì†Œë€' : 'í˜ë¥´ì†Œë‚˜', 'ë¼íŒ¡':'ë¼ì´í”„íŒŒí¬', 
        'ASI': 'ê³„ë¦¬ì‚¬ 1ì°¨', 'ë¶€ì¡°ìš©ì‹¤':'ë¶€ì¡°ì •ì‹¤', 'ë‹¤ë²¤ì¹˜':'ë‹¤ë¹ˆì¹˜','ì¸ì‚¬íŠ¸':'ì¸ì‚¬ì´íŠ¸',
        'ì•ˆë³´í—˜': 'ì•”ë³´í—˜','ì¤‘ì‹¬íŒŒíŠ¸': 'ì¢…ì‹ íŒŒíŠ¸','ì¤‘ì‹¬ë³´í—˜': 'ì¢…ì‹ ë³´í—˜','ì§€í•˜ì˜ë³´í—˜': 'GIë³´í—˜','ê°œë¦¬ì§€ì›íŒ€': 'ê³„ë¦¬ì§€ì›íŒ€','ì„ ì„ê°œë¦¬íŒŒíŠ¸': 'ì„ ì„ê³„ë¦¬íŒŒíŠ¸',
'ê°œë¦¬': 'ê³„ë¦¬',
'ë³´í—˜ê°œë¦¬ì‚¬': 'ë³´í—˜ê³„ë¦¬ì‚¬',
'ê°œë¦¬ì§ë¬´': 'ê³„ë¦¬ì§ë¬´',
'êµ­ì–´ ê³µë¬¸í•™ì ': 'êµ­ì–´ êµ­ë¬¸í•™ì ',
'ë‘ê°ˆì‹': 'ë‘ê´„ì‹',
'í•˜ë‚˜ ìƒëª…': 'í•œí™”ìƒëª…',
'í•˜ë‚˜ ì´ê¸€ìŠ¤': 'í•œí™”ì´ê¸€ìŠ¤',
'ìƒë¶€ì—…ê³„': 'ìƒë³´ì—…ê³„',
'ì´ë°ì´': 'ì´ëŒ€í¬'
}

    # Replace words in all docs
    for doc in docs:
        if hasattr(doc, 'page_content'):
            doc.page_content = (
                doc.page_content
                if not any(old in doc.page_content for old in replace_pairs)
                else reduce(lambda text, pair: text.replace(pair[0], pair[1]), replace_pairs.items(), doc.page_content)
            )

    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ë²¡í„°í™”
    combined_docs = [doc.page_content for doc in docs]
    text = " ".join(combined_docs)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)
    splits = text_splitter.split_text(text)
    embeddings = OpenAIEmbeddings()
    vectordb = FAISS.from_texts(splits, embeddings)

    # ì½œë°± í•¸ë“¤ëŸ¬ í´ë˜ìŠ¤ ì •ì˜
    class StreamCallback(BaseCallbackHandler):
        def on_llm_new_token(self, token: str, **kwargs):
            st.text(f"{token}")

    st.session_state["qa_chain"] = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(
            model_name="gpt-4o",
            temperature=0,
            streaming=True,
            callbacks=[StreamCallback()],
        ),
        chain_type="stuff",
        retriever=vectordb.as_retriever(),
    )

# Streamlit Query UI
st.title("ì§í„°ë·° ğŸ§‘â€âš•ï¸")
st.text("ê¶ê¸ˆí•˜ì‹  ì •ë³´ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš” ğŸ” ")

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
if st.session_state["chat_answer_history"]:
    for index, (query, answer) in enumerate(zip(st.session_state["user_prompt_history"], st.session_state["chat_answer_history"])):
        widget_key1 = f"query_{index}"
        widget_key2 = f"ans_{index}"
        message(query, is_user=True, key=widget_key1)
        message(answer, key=widget_key2)

# ì‚¬ìš©ì ì…ë ¥ê³¼ ì œì¶œ ë²„íŠ¼ì„ í•œ ì¤„ë¡œ ë°°ì¹˜
with st.form("form"):
    cols = st.columns([8, 1])  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ ì…ë ¥ë€, ë‘ ë²ˆì§¸ëŠ” ë²„íŠ¼
    user_input = cols[0].text_input("ê¶ê¸ˆí•˜ì‹  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.", key="user_input", label_visibility="collapsed")
    submit = cols[1].form_submit_button("ë¬¼ì–´ë³´ê¸°")

# ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ QA ì‘ë‹µ ìƒì„±
if user_input and submit:
    # ìŠ¤í”¼ë„ˆë¥¼ í”„ë¡¬í”„íŠ¸ ìœ„ì— í‘œì‹œ
    with st.spinner("ë‹µë³€ ìƒì„±ì¤‘..."):
        response = st.session_state["qa_chain"].run(user_input)

        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        st.session_state["user_prompt_history"].append(user_input)
        st.session_state["chat_answer_history"].append(response)
        st.session_state["chat_history"].append((user_input, response))

    # ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ì¶”ê°€ëœ í›„ ëŒ€í™” ê¸°ë¡ ê°±ì‹ 
    st.experimental_rerun()

# # requirements.txt ìƒì„±
# def generate_requirements():
#     requirements = [
#         "streamlit",
#         "python-dotenv",
#         "streamlit-chat",
#         "langchain-openai",
#         "langchain-community",
#         "faiss-cpu",
#     ]
#     with open("requirements.txt", "w") as f:
#         f.write("\n".join(requirements))

# generate_requirements()

# # packages.txt ìƒì„±
# def generate_packages():
#     packages = [
#         "ffmpeg",  # For handling YouTube audio files
#     ]
#     with open("packages.txt", "w") as f:
#         f.write("\n".join(packages))

# generate_packages()
